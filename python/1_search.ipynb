{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Build a Similarity Search for YouTube Transcripts\n",
    "\n",
    "In this notebook, you will use the AzureOpenAI client to get the text embeddings of a string and perform a cosine similarity comparison against the transcripts from [Boston Azure Youtube channel](https://www.youtube.com/bostonazure) to find the videos with the highest similarity.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "* Load the variables in the .env file\n",
    "* Connect to AzureOpenAI in python\n",
    "* Load the transcript file and create a pandas data frame\n",
    "* Calculate the similarity of a transcript's embeddings to the text embedding\n",
    "* Output the most similar videos with a url formatted to navigate to the 5 min section that was found most similiar\n",
    "\n",
    "### Step 1: load environment variables and create the AzureOpenAI client\n",
    "\n",
    "> NOTE:\n",
    "> \n",
    "> If you have not selected a kernel for the notebook yet, you will be asked to do so when you select the **execute cell** button. Select **Python Environments**, the the **.venv environment** you setup in the initial setup.\n",
    ">\n",
    "> If this is the first time you have run a Jupyter notebook, you will be asked to install the **ipykernel** package. **Click on Install** when the dialog comes up.\n",
    ">\n",
    "> This will take a minute or two to install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.2.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Using cached numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/rakeshchoudhury/Git/AzureAILab/AzureAI/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/rakeshchoudhury/Git/AzureAILab/AzureAI/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Using cached pandas-2.2.2-cp312-cp312-macosx_11_0_arm64.whl (11.3 MB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl (13.7 MB)\n",
      "Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-1.26.4 pandas-2.2.2 pytz-2024.1 tzdata-2024.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Using cached openai-1.23.2-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Using cached anyio-4.3.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Using cached httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Using cached pydantic-2.7.0-py3-none-any.whl.metadata (103 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Using cached tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting typing-extensions<5,>=4.7 (from openai)\n",
      "  Using cached typing_extensions-4.11.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai)\n",
      "  Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.18.1 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached pydantic_core-2.18.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.5 kB)\n",
      "Using cached openai-1.23.2-py3-none-any.whl (311 kB)\n",
      "Using cached anyio-4.3.0-py3-none-any.whl (85 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "Using cached httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "Using cached pydantic-2.7.0-py3-none-any.whl (407 kB)\n",
      "Using cached pydantic_core-2.18.1-cp312-cp312-macosx_11_0_arm64.whl (1.8 MB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "Using cached typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
      "Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Using cached certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: typing-extensions, tqdm, sniffio, idna, h11, distro, certifi, annotated-types, pydantic-core, httpcore, anyio, pydantic, httpx, openai\n",
      "Successfully installed annotated-types-0.6.0 anyio-4.3.0 certifi-2024.2.2 distro-1.9.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 idna-3.7 openai-1.23.2 pydantic-2.7.0 pydantic-core-2.18.1 sniffio-1.3.1 tqdm-4.66.2 typing-extensions-4.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "  api_version = \"2024-02-01\",\n",
    "  azure_endpoint =os.getenv(\"AZURE_OPENAI_ENDPOINT\") \n",
    "  )\n",
    "\n",
    "model = os.getenv(\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Set the threshold for the similarity score we want to use and version of the transcript file.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMILARITIES_RESULTS_THRESHOLD = 0.70\n",
    "DATASET_NAME = \"./prep/output/master_enriched.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create some utility methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(source: str) -> pd.core.frame.DataFrame:\n",
    "    pd_vectors = pd.read_json(source)\n",
    "    return pd_vectors.drop(columns=[\"text\"], errors=\"ignore\").fillna(\"\")\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def get_videos(\n",
    "    query: str, dataset: pd.core.frame.DataFrame, rows: int\n",
    ") -> pd.core.frame.DataFrame:\n",
    "    # create a copy of the dataset\n",
    "    video_vectors = dataset.copy()\n",
    "\n",
    "    # get the embeddings for the query    \n",
    "    query_embeddings = client.embeddings.create(input=query, model=model).data[0].embedding\n",
    "\n",
    "    # create a new column with the calculated similarity for each row\n",
    "    video_vectors[\"similarity\"] = video_vectors[\"ada_v2\"].apply(\n",
    "        lambda x: cosine_similarity(np.array(query_embeddings), np.array(x))\n",
    "    )\n",
    "\n",
    "    # filter the videos by similarity\n",
    "    mask = video_vectors[\"similarity\"] >= SIMILARITIES_RESULTS_THRESHOLD\n",
    "    video_vectors = video_vectors[mask].copy()\n",
    "\n",
    "    # sort the videos by similarity\n",
    "    video_vectors = video_vectors.sort_values(by=\"similarity\", ascending=False).head(\n",
    "        rows\n",
    "    )\n",
    "\n",
    "    # return the top rows\n",
    "    return video_vectors.head(rows)\n",
    "\n",
    "def display_results(videos: pd.core.frame.DataFrame, query: str):\n",
    "    def _gen_yt_url(video_id: str, seconds: int) -> str:\n",
    "        \"\"\"convert time in format 00:00:00 to seconds\"\"\"\n",
    "        return f\"https://youtu.be/{video_id}?t={seconds}\"\n",
    "\n",
    "    print(f\"\\nVideos similar to '{query}':\")\n",
    "    print(f\"\")\n",
    "    for _, row in videos.iterrows():\n",
    "        youtube_url = _gen_yt_url(row[\"videoId\"], row[\"seconds\"])\n",
    "        print(f\" - {row['title']}\")\n",
    "        print(f\"   YouTube: {youtube_url}\")\n",
    "        print(f\"   Similarity: {row['similarity']}\")\n",
    "        print(f\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Load the transcript file (and take a look at what is in it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_vectors = load_dataset(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this version of the transcripts file has the embeddings in it already for the 5 minute chunks of the transcript text. The embeddings are the ada_v2 column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>title</th>\n",
       "      <th>videoId</th>\n",
       "      <th>description</th>\n",
       "      <th>start</th>\n",
       "      <th>seconds</th>\n",
       "      <th>ada_v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>Map Azure DevOps Runtime Variables to Terrafor...</td>\n",
       "      <td>-ssTKjHVP_Q</td>\n",
       "      <td>This is a recording of the March 29, 2023 virt...</td>\n",
       "      <td>00:00:02</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.019308112561702003, -0.024012072011828003,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>Map Azure DevOps Runtime Variables to Terrafor...</td>\n",
       "      <td>-ssTKjHVP_Q</td>\n",
       "      <td>This is a recording of the March 29, 2023 virt...</td>\n",
       "      <td>00:05:04</td>\n",
       "      <td>304</td>\n",
       "      <td>[-0.0006771119078620001, -0.007956171408295, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>Map Azure DevOps Runtime Variables to Terrafor...</td>\n",
       "      <td>-ssTKjHVP_Q</td>\n",
       "      <td>This is a recording of the March 29, 2023 virt...</td>\n",
       "      <td>00:10:07</td>\n",
       "      <td>607</td>\n",
       "      <td>[-0.01619478687644, -0.020837383344769003, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>Map Azure DevOps Runtime Variables to Terrafor...</td>\n",
       "      <td>-ssTKjHVP_Q</td>\n",
       "      <td>This is a recording of the March 29, 2023 virt...</td>\n",
       "      <td>00:15:10</td>\n",
       "      <td>910</td>\n",
       "      <td>[-0.011464371345937, -0.032427001744508, -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>Map Azure DevOps Runtime Variables to Terrafor...</td>\n",
       "      <td>-ssTKjHVP_Q</td>\n",
       "      <td>This is a recording of the March 29, 2023 virt...</td>\n",
       "      <td>00:20:16</td>\n",
       "      <td>1216</td>\n",
       "      <td>[-0.015697304159402, -0.015205482952296002, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td></td>\n",
       "      <td>Udai Ramachandran: Azure Front Door</td>\n",
       "      <td>vTLZ3GoZZvI</td>\n",
       "      <td>This is a recording of the September 14, 2021 ...</td>\n",
       "      <td>00:55:35</td>\n",
       "      <td>3335</td>\n",
       "      <td>[0.010421303100883001, 0.022980673238635, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td></td>\n",
       "      <td>Udai Ramachandran: Azure Front Door</td>\n",
       "      <td>vTLZ3GoZZvI</td>\n",
       "      <td>This is a recording of the September 14, 2021 ...</td>\n",
       "      <td>01:00:38</td>\n",
       "      <td>3638</td>\n",
       "      <td>[0.011888379231095002, 0.0041570011526340005, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td></td>\n",
       "      <td>Udai Ramachandran: Azure Front Door</td>\n",
       "      <td>vTLZ3GoZZvI</td>\n",
       "      <td>This is a recording of the September 14, 2021 ...</td>\n",
       "      <td>01:05:45</td>\n",
       "      <td>3945</td>\n",
       "      <td>[0.015738856047391, 0.008334751240909, 0.02017...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td></td>\n",
       "      <td>Udai Ramachandran: Azure Front Door</td>\n",
       "      <td>vTLZ3GoZZvI</td>\n",
       "      <td>This is a recording of the September 14, 2021 ...</td>\n",
       "      <td>01:10:48</td>\n",
       "      <td>4248</td>\n",
       "      <td>[0.010681172832846001, 0.005410764832049, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td></td>\n",
       "      <td>Udai Ramachandran: Azure Front Door</td>\n",
       "      <td>vTLZ3GoZZvI</td>\n",
       "      <td>This is a recording of the September 14, 2021 ...</td>\n",
       "      <td>01:15:52</td>\n",
       "      <td>4552</td>\n",
       "      <td>[-0.012935931794345, 0.0024897092953320003, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    speaker                                              title      videoId  \\\n",
       "0            Map Azure DevOps Runtime Variables to Terrafor...  -ssTKjHVP_Q   \n",
       "1            Map Azure DevOps Runtime Variables to Terrafor...  -ssTKjHVP_Q   \n",
       "2            Map Azure DevOps Runtime Variables to Terrafor...  -ssTKjHVP_Q   \n",
       "3            Map Azure DevOps Runtime Variables to Terrafor...  -ssTKjHVP_Q   \n",
       "4            Map Azure DevOps Runtime Variables to Terrafor...  -ssTKjHVP_Q   \n",
       "..      ...                                                ...          ...   \n",
       "147                        Udai Ramachandran: Azure Front Door  vTLZ3GoZZvI   \n",
       "148                        Udai Ramachandran: Azure Front Door  vTLZ3GoZZvI   \n",
       "149                        Udai Ramachandran: Azure Front Door  vTLZ3GoZZvI   \n",
       "150                        Udai Ramachandran: Azure Front Door  vTLZ3GoZZvI   \n",
       "151                        Udai Ramachandran: Azure Front Door  vTLZ3GoZZvI   \n",
       "\n",
       "                                           description     start  seconds  \\\n",
       "0    This is a recording of the March 29, 2023 virt...  00:00:02        2   \n",
       "1    This is a recording of the March 29, 2023 virt...  00:05:04      304   \n",
       "2    This is a recording of the March 29, 2023 virt...  00:10:07      607   \n",
       "3    This is a recording of the March 29, 2023 virt...  00:15:10      910   \n",
       "4    This is a recording of the March 29, 2023 virt...  00:20:16     1216   \n",
       "..                                                 ...       ...      ...   \n",
       "147  This is a recording of the September 14, 2021 ...  00:55:35     3335   \n",
       "148  This is a recording of the September 14, 2021 ...  01:00:38     3638   \n",
       "149  This is a recording of the September 14, 2021 ...  01:05:45     3945   \n",
       "150  This is a recording of the September 14, 2021 ...  01:10:48     4248   \n",
       "151  This is a recording of the September 14, 2021 ...  01:15:52     4552   \n",
       "\n",
       "                                                ada_v2  \n",
       "0    [-0.019308112561702003, -0.024012072011828003,...  \n",
       "1    [-0.0006771119078620001, -0.007956171408295, 0...  \n",
       "2    [-0.01619478687644, -0.020837383344769003, -0....  \n",
       "3    [-0.011464371345937, -0.032427001744508, -0.01...  \n",
       "4    [-0.015697304159402, -0.015205482952296002, 0....  \n",
       "..                                                 ...  \n",
       "147  [0.010421303100883001, 0.022980673238635, 0.00...  \n",
       "148  [0.011888379231095002, 0.0041570011526340005, ...  \n",
       "149  [0.015738856047391, 0.008334751240909, 0.02017...  \n",
       "150  [0.010681172832846001, 0.005410764832049, -0.0...  \n",
       "151  [-0.012935931794345, 0.0024897092953320003, 0....  \n",
       "\n",
       "[152 rows x 7 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Try it out\n",
    "\n",
    "I've put some default text in for a good example, but you should change the query to your own search and see what comes back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Videos similar to 'What is langchain?':\n",
      "\n",
      " - Pamela Fox: Building a RAG app to chat with your data\n",
      "   YouTube: https://youtu.be/3Zh9MEuyTQo?t=4260\n",
      "   Similarity: 0.7424003538820972\n",
      "\n",
      " - Deploy Your GO API to Azure Functions\n",
      "   YouTube: https://youtu.be/1NcnkU403UE?t=305\n",
      "   Similarity: 0.7225723356406508\n",
      "\n",
      " - Deploy Your GO API to Azure Functions\n",
      "   YouTube: https://youtu.be/1NcnkU403UE?t=2\n",
      "   Similarity: 0.7213426954452004\n",
      "\n",
      " - Deploy Your GO API to Azure Functions\n",
      "   YouTube: https://youtu.be/1NcnkU403UE?t=1819\n",
      "   Similarity: 0.717694984189706\n",
      "\n",
      " - Monitor Azure Resources with Kusto Query Language with Taiob Ali\n",
      "   YouTube: https://youtu.be/6u-yWHNBCAg?t=2125\n",
      "   Similarity: 0.7135936233681079\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is langchain?\"\n",
    "\n",
    "videos = get_videos(query, pd_vectors, 5)\n",
    "display_results(videos, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Reference\n",
    "This code is a modified version of this notebook: [ai-beginners-embeddings](https://github.com/gloveboxes/ai-beginners-embeddings/blob/main/main.ipynb)\n",
    "\n",
    "\n",
    "## [Go To Next Lab](./2_rag.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
